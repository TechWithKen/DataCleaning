{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "491ff08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_filename(path):\n",
    "    filename = os.path.basename(path)\n",
    "    name = re.split(r'[_\\.]', filename)[0]\n",
    "\n",
    "    key = name[:3]\n",
    "    return key\n",
    "\n",
    "\n",
    "\n",
    "def get_r_re_filename(path):\n",
    "    name = os.path.basename(path)\n",
    "    name = name.rsplit(\".\", 1)[0]         \n",
    "    name = name.replace(\"_RE\", \"\").replace(\"_R\", \"\")\n",
    "    return name\n",
    "\n",
    "\n",
    "\n",
    "def get_peptide_isr(folder_path):\n",
    "    c_peptide_values = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(\"txt\") and not f.lower().endswith((\"_re.txt\", \"_r.txt\",))]\n",
    "    isr_values = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith((\"_re.txt\", \"_r.txt\"))]\n",
    "\n",
    "\n",
    "    c_peptide_database = {}\n",
    "    isr_values_database = {}\n",
    "\n",
    "    for file in c_peptide_values:\n",
    "\n",
    "        key = get_filename(file)\n",
    "\n",
    "        if key not in c_peptide_database:\n",
    "            c_peptide_database[key] = []\n",
    "\n",
    "\n",
    "        c_peptide_database[key].append(file)\n",
    "\n",
    "    for file in isr_values:\n",
    "        key = get_filename(file)\n",
    "\n",
    "\n",
    "        if key not in isr_values_database:\n",
    "            isr_values_database[key] = []\n",
    "\n",
    "\n",
    "        isr_values_database[key].append(file)\n",
    "\n",
    "    return {\"C_peptide\": c_peptide_database, \"ISR\": isr_values_database}\n",
    "\n",
    "path_to_folder = \"/Users/alert/Desktop/ISEC/ISR-PEPTIDE-TXT/\"\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_file(filename, col_name=None):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = {}\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    df_meta = pd.DataFrame(\n",
    "        metadata.items(),\n",
    "        columns=[\"TIME(min)\", \"C_PEPTIDE\"]\n",
    "    )\n",
    "\n",
    "    table_start = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"TIME (min)\" in line and \"C-PEPTIDE\" in line:\n",
    "            table_start = i + 1 \n",
    "            break\n",
    "\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        sep=r\"\\s+\",\n",
    "        skiprows=table_start,\n",
    "        engine=\"python\",\n",
    "        names=[\"TIME(min)\", \"C_PEPTIDE\"],\n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "\n",
    "\n",
    "    new_dataframe  = pd.concat([df, df_meta])\n",
    "    datasetframe = new_dataframe.reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "    # Optonally rename the column to avoid conflicts when merging\n",
    "    if col_name:\n",
    "        datasetframe.rename(columns={\"C_PEPTIDE\": col_name}, inplace=True)\n",
    "\n",
    "    return datasetframe, metadata[\"ID\"]\n",
    "\n",
    "\n",
    "c_pep = get_peptide_isr(path_to_folder)[\"C_peptide\"]\n",
    "c_pep_dataframes = {}\n",
    "for files in c_pep:\n",
    "    \n",
    "    c_pep_final_df = preprocess_file(c_pep[files][0], col_name=f\"{preprocess_file(c_pep[files][0])[1]}\")[0]\n",
    "    \n",
    "\n",
    "    # Step 2: Loop through the rest and merge\n",
    "    for idx, file in enumerate(c_pep[files][1:], start=2):\n",
    "        id = preprocess_file(file)[1]\n",
    "        \n",
    "        key = get_filename(file)\n",
    "        df_new = preprocess_file(file, col_name=f\"{id}.\")[0]\n",
    "        c_pep_final_df = pd.merge(c_pep_final_df, df_new, on=\"TIME(min)\", how=\"outer\")\n",
    "\n",
    "    key = get_filename(files)\n",
    "\n",
    "    if key not in c_pep_dataframes:\n",
    "        c_pep_dataframes[key] = c_pep_final_df\n",
    "\n",
    "\n",
    "nap = c_pep_dataframes[\"NAP\"]\n",
    "nap.rename(columns=lambda c: f\"N{c}\" if c.startswith(\"APR\") else c, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ISR File Manipulation#####\n",
    "isr = get_peptide_isr(path_to_folder)[\"ISR\"]\n",
    "\n",
    "file_database = isr\n",
    "\n",
    "def preprocess_isr(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    table_start = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"from\" in line and \"to\" in line:\n",
    "            table_start = i + 1\n",
    "            break\n",
    "\n",
    "  \n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        sep=r\"\\s+\",\n",
    "        skiprows=table_start,\n",
    "        engine=\"python\",\n",
    "        names=[\"from\", \"to\", \"isr\"],\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "\n",
    "\n",
    "    df.loc[df.index[0], \"isr\"] = df.loc[df.index[0], \"to\"]\n",
    "    df.loc[df.index[0], \"to\"]  = df.loc[df.index[0], \"from\"]\n",
    "\n",
    "\n",
    "    mask = df.isna().any(axis=1)\n",
    "    first_none_idx = mask.idxmax() if mask.any() else len(df)\n",
    "    df = df.iloc[:first_none_idx]\n",
    "\n",
    "    subject = get_r_re_filename(filepath).upper()\n",
    "\n",
    "    df = (\n",
    "        df.drop(columns=[\"from\"])\n",
    "          .rename(columns={\n",
    "              \"to\": \"TIME(min)\",\n",
    "              \"isr\": subject\n",
    "          })\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_isr_dataframe():\n",
    "    isr_dataframe = {}\n",
    "\n",
    "    for group, group_files in file_database.items():\n",
    "\n",
    "        isr_final_df = None\n",
    "\n",
    "        for file in group_files:\n",
    "            df = preprocess_isr(file)\n",
    "\n",
    "            if isr_final_df is None:\n",
    "                isr_final_df = df\n",
    "            else:\n",
    "                isr_final_df = pd.merge(\n",
    "                    isr_final_df,\n",
    "                    df,\n",
    "                    on=\"TIME(min)\",\n",
    "                    how=\"outer\"   # IMPORTANT\n",
    "                )\n",
    "            key = get_filename(file)\n",
    "\n",
    "        isr_final_df = isr_final_df.sort_values(\"TIME(min)\").reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        if key not in isr_dataframe:\n",
    "            isr_dataframe[key] = isr_final_df\n",
    "            \n",
    "    return isr_dataframe\n",
    "\n",
    "def expand_isr(dataframe_to_expand):\n",
    "    insulin_df = dataframe_to_expand.melt(\n",
    "    id_vars=[\"TIME(min)\"],\n",
    "    var_name=\"sample\",\n",
    "    value_name=\"ISR\",\n",
    ")\n",
    "    insulin_df[\"sample_id\"] = insulin_df[\"sample\"].astype(\"category\").cat.codes + 1\n",
    "\n",
    "    insulin_df = insulin_df.sort_values(by=[\"sample_id\", \"TIME(min)\"], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "    insulin_df\n",
    "    return insulin_df\n",
    "\n",
    "\n",
    "\n",
    "# print(create_isr_dataframe()[\"JAN\"])\n",
    "def expand_dataframe(dataframe_to_expand):\n",
    "\n",
    "\n",
    "    each_month_dataframe = dataframe_to_expand.copy()\n",
    "    age_idx = each_month_dataframe.index[each_month_dataframe[\"TIME(min)\"].isin([\"AGE\", \"ID\"])][0]\n",
    "    top_dataframe = each_month_dataframe.iloc[:age_idx]\n",
    "    bottom_dataframe = each_month_dataframe.iloc[age_idx:]\n",
    "\n",
    "    expand_top = top_dataframe.melt(\n",
    "        id_vars=[\"TIME(min)\"],\n",
    "        var_name=\"sample\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "    expand_top[\"sample_id\"] = expand_top[\"sample\"].astype(\"category\").cat.codes + 1\n",
    "\n",
    "    expand_top = expand_top.sort_values(by=[\"sample_id\", \"TIME(min)\"], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    expand_bottom = bottom_dataframe\n",
    "\n",
    "    expand_bottom = expand_bottom.set_index(\"TIME(min)\")\n",
    "    expand_bottom = expand_bottom.T\n",
    "\n",
    "\n",
    "    expand_bottom = expand_bottom.reset_index()\n",
    "    numeric_cols = [\"AGE\", \"HEIGHT\", \"ID\", \"SEX\", \"SUBJECT\", \"WEIGHT\"]\n",
    "    expand_bottom.rename(columns={\"index\":\"Sample_ID\"}, inplace=True)\n",
    "\n",
    "\n",
    "    expand_top = expand_top.merge(\n",
    "        expand_bottom[[\"Sample_ID\", \"AGE\", \"HEIGHT\", \"ID\", \"SEX\", \"SUBJECT\", \"WEIGHT\"]],\n",
    "        left_on=\"sample\", \n",
    "        right_on=\"Sample_ID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "    expand_top = (\n",
    "        expand_top.drop(columns=[\"sample\"]).rename(columns={\"value\": \"C-Peptide\"})\n",
    "    )\n",
    "\n",
    "    expand_top[\"C-Peptide\"] = pd.to_numeric(expand_top[\"C-Peptide\"], errors=\"coerce\")\n",
    "    return expand_top\n",
    "\n",
    "\n",
    "\n",
    "ultimate_dataframe = pd.DataFrame()\n",
    "current_max_sample_id = 0\n",
    "\n",
    "for pick_month in c_pep_dataframes:\n",
    "\n",
    "    if pick_month == \"nap\": \n",
    "        final_dataframe = nap\n",
    "    final_dataframe = expand_dataframe(c_pep_dataframes[pick_month.upper()])\n",
    "    insulin = expand_isr(create_isr_dataframe()[pick_month.upper()])\n",
    "\n",
    "\n",
    "    final_dataframe[\"ID\"] = final_dataframe[\"Sample_ID\"]\n",
    "    final_dataframe.drop(columns=[\"Sample_ID\"], inplace=True)\n",
    "    final_dataframe[\"ID\"] = (\n",
    "        final_dataframe[\"ID\"]\n",
    "        .str.translate(str.maketrans({\" \": \"\", \".\": \"\"}))\n",
    "    )\n",
    "\n",
    "\n",
    "    final_dataframe = pd.merge(final_dataframe, insulin, left_on=[\"TIME(min)\", \"ID\"], right_on=[\"TIME(min)\", \"sample\"], how=\"inner\")\n",
    "    final_dataframe.rename(columns={\"sample_id_x\":\"Sample ID\"}, inplace=True)\n",
    "    final_dataframe.drop(columns=[\"ID\", \"sample_id_y\"], inplace=True)\n",
    "    final_dataframe[\"Sample ID\"] = (\n",
    "        final_dataframe[\"Sample ID\"] + current_max_sample_id\n",
    "    )\n",
    "\n",
    "    # update max Sample ID\n",
    "    current_max_sample_id = final_dataframe[\"Sample ID\"].max()\n",
    "\n",
    "    # concatenate\n",
    "    ultimate_dataframe = pd.concat(\n",
    "        [ultimate_dataframe, final_dataframe],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "ultimate_dataframe.to_excel(\"fulldataset.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2a950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
