{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd3453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ead56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "491ff08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CON', 'FEB', 'SEP', 'OCT', 'MAR', 'JAN', 'DEC', 'AUG', 'NAP', 'TES', 'M2', 'APR', 'M3', 'M1', 'M4', 'JUL', 'M11', 'DIA', 'M33', 'M51', 'M52'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_filename(path):\n",
    "    filename = os.path.basename(path)\n",
    "    name = re.split(r'[_\\.]', filename)[0]\n",
    "\n",
    "    key = name[:3]\n",
    "    return key\n",
    "\n",
    "def get_peptide_isr(folder_path):\n",
    "    c_peptide_values = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(\"txt\") and not f.lower().endswith((\"_re.txt\", \"_r.txt\",))]\n",
    "    isr_values = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith((\"_re.txt\", \"_r.txt\"))]\n",
    "\n",
    "\n",
    "    c_peptide_database = {}\n",
    "    isr_values_database = {}\n",
    "\n",
    "    for file in c_peptide_values:\n",
    "\n",
    "        key = get_filename(file)\n",
    "\n",
    "        if key not in c_peptide_database:\n",
    "            c_peptide_database[key] = []\n",
    "\n",
    "\n",
    "        c_peptide_database[key].append(file)\n",
    "\n",
    "    for file in isr_values:\n",
    "        key = file\n",
    "\n",
    "\n",
    "        if key not in isr_values_database:\n",
    "            isr_values_database[key] = []\n",
    "\n",
    "\n",
    "        isr_values_database[key].append(file)\n",
    "\n",
    "    return {\"C_peptide\": c_peptide_database, \"ISR\": isr_values_database}\n",
    "\n",
    "path_to_folder = \"/Users/alert/Desktop/ISEC/ISR-PEPTIDE-TXT/\"\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_file(filename, col_name=None):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = {}\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    df_meta = pd.DataFrame(\n",
    "        metadata.items(),\n",
    "        columns=[\"TIME(min)\", \"C_PEPTIDE\"]\n",
    "    )\n",
    "\n",
    "    table_start = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"TIME (min)\" in line and \"C-PEPTIDE\" in line:\n",
    "            table_start = i + 1 \n",
    "            break\n",
    "\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        sep=r\"\\s+\",\n",
    "        skiprows=table_start,\n",
    "        engine=\"python\",\n",
    "        names=[\"TIME(min)\", \"C_PEPTIDE\"],\n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "\n",
    "\n",
    "    new_dataframe  = pd.concat([df, df_meta])\n",
    "    datasetframe = new_dataframe.reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "    # Optonally rename the column to avoid conflicts when merging\n",
    "    if col_name:\n",
    "        datasetframe.rename(columns={\"C_PEPTIDE\": col_name}, inplace=True)\n",
    "\n",
    "    return datasetframe, metadata[\"ID\"]\n",
    "\n",
    "\n",
    "c_pep = get_peptide_isr(path_to_folder)[\"C_peptide\"]\n",
    "c_pep_dataframes = {}\n",
    "for files in c_pep:\n",
    "    \n",
    "    final_df = preprocess_file(c_pep[files][0], col_name=f\"{preprocess_file(c_pep[files][0])[1]}\")[0]\n",
    "    \n",
    "\n",
    "    # Step 2: Loop through the rest and merge\n",
    "    for idx, file in enumerate(c_pep[files][1:], start=2):\n",
    "        id = preprocess_file(file)[1]\n",
    "        \n",
    "        key = get_filename(file)\n",
    "        df_new = preprocess_file(file, col_name=f\"{id}.\")[0]\n",
    "        final_df = pd.merge(final_df, df_new, on=\"TIME(min)\", how=\"outer\")\n",
    "\n",
    "    key = get_filename(files)\n",
    "\n",
    "    if key not in c_pep_dataframes:\n",
    "        c_pep_dataframes[key] = final_df\n",
    "\n",
    "\n",
    "\n",
    "c_pep_dataframes.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976033f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mprint\u001b[39m(get_filename(isr))\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m isr:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpreprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# if filename.endswith(\"RE.TXT\"):\u001b[39;00m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m#     subject = filename.replace(\"_RE.TXT\", \"\")\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# elif filename.endswith(\"R.TXT\"):\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# print(\"\\n✅ All groups successfully written to Excel.\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mpreprocess_file\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     46\u001b[39m     key = name\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m key\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43misr\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mpreprocess_file.<locals>.get_filename\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_filename\u001b[39m(path):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     filename = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     name = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[_\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m, filename)[\u001b[32m0\u001b[39m]\n\u001b[32m     46\u001b[39m     key = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen posixpath>:168\u001b[39m, in \u001b[36mbasename\u001b[39m\u001b[34m(p)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbasename\u001b[39m(p):\n\u001b[32m    167\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the final component of a pathname\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     p = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     sep = _get_sep(p)\n\u001b[32m    170\u001b[39m     i = p.rfind(sep) + \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: expected str, bytes or os.PathLike object, not dict"
     ]
    }
   ],
   "source": [
    "isr = get_peptide_isr(path_to_folder)[\"ISR\"]\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# STEP 2: PREPROCESS A SINGLE FILE\n",
    "# ================================\n",
    "\n",
    "def preprocess_file(filepath):\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find table start\n",
    "    table_start = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"from\" in line and \"to\" in line:\n",
    "            table_start = i + 1\n",
    "            break\n",
    "\n",
    "    # Read table\n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        sep=r\"\\s+\",\n",
    "        skiprows=table_start,\n",
    "        engine=\"python\",\n",
    "        names=[\"from\", \"to\", \"isr\"],\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "\n",
    "    # Fix first row\n",
    "    df.loc[df.index[0], \"isr\"] = df.loc[df.index[0], \"to\"]\n",
    "    df.loc[df.index[0], \"to\"]  = df.loc[df.index[0], \"from\"]\n",
    "\n",
    "    # Stop at first NaN row\n",
    "    mask = df.isna().any(axis=1)\n",
    "    first_none_idx = mask.idxmax() if mask.any() else len(df)\n",
    "    df = df.iloc[:first_none_idx]\n",
    "\n",
    "    subject=\"\"\n",
    "\n",
    "    def get_filename(path):\n",
    "        filename = os.path.basename(path)\n",
    "        name = re.split(r'[_\\]', filename)[0]\n",
    "\n",
    "        key = name\n",
    "        return key\n",
    "    # print(get_filename(isr[\"CON\"]))\n",
    "\n",
    "\n",
    "for i in isr:\n",
    "    print(preprocess_file(i))\n",
    "\n",
    "\n",
    "    # if filename.endswith(\"RE.TXT\"):\n",
    "    #     subject = filename.replace(\"_RE.TXT\", \"\")\n",
    "    # elif filename.endswith(\"R.TXT\"):\n",
    "    #     subject = filename.replace(\"_R.TXT\", \"\")\n",
    "    # else:\n",
    "    #     subject = subject\n",
    "\n",
    "    # # Final clean dataframe\n",
    "    # df = (\n",
    "    #     df.drop(columns=[\"from\"])\n",
    "    #       .rename(columns={\n",
    "    #           \"to\": \"TIME(min)\",\n",
    "    #           \"isr\": subject\n",
    "    #       })\n",
    "    # )\n",
    "\n",
    "    # return df\n",
    "\n",
    "\n",
    "# ================================\n",
    "# STEP 3: MERGE & WRITE TO EXCEL\n",
    "# ================================\n",
    "\n",
    "# output_file = \"ALL_ISR_GROUPS.xlsx\"\n",
    "\n",
    "# with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "\n",
    "#     for group, group_files in file_database.items():\n",
    "#         print(f\"\\nProcessing group: {group}\")\n",
    "\n",
    "#         final_df = None\n",
    "\n",
    "#         for file in group_files:\n",
    "#             df = preprocess_file(folder_path, file)\n",
    "\n",
    "#             if final_df is None:\n",
    "#                 final_df = df\n",
    "#             else:\n",
    "#                 final_df = pd.merge(\n",
    "#                     final_df,\n",
    "#                     df,\n",
    "#                     on=\"TIME(min)\",\n",
    "#                     how=\"outer\"   # IMPORTANT\n",
    "#                 )\n",
    "\n",
    "#         final_df = final_df.sort_values(\"TIME(min)\").reset_index(drop=True)\n",
    "#         final_df.to_excel(writer, sheet_name=group, index=False)\n",
    "\n",
    "# print(\"\\n✅ All groups successfully written to Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c59e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
